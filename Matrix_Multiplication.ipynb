{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOqfTdpUoYzHmV3+cbk5WdF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shrutika-TechSavvy/Google-Colab-Codes/blob/main/Matrix_Multiplication.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VI4lUeQqqwof",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "857fe1ee-2524-4bd8-d17c-06f0de223214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_mul_colab.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile matrix_mul_colab.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "#define N 3\n",
        "\n",
        "__global__ void matMul(int *A, int *B, int *C, int n) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < n && col < n) {\n",
        "        int sum = 0;\n",
        "        for (int k = 0; k < n; ++k)\n",
        "            sum += A[row * n + k] * B[k * n + col];\n",
        "        C[row * n + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size = N*N*sizeof(int);\n",
        "    int h_A[N*N], h_B[N*N], h_C[N*N];\n",
        "\n",
        "    // Initialize matrices\n",
        "    for (int i = 0; i < N*N; i++) {\n",
        "        h_A[i] = i + 1;\n",
        "        h_B[i] = (i + 1) * 2;\n",
        "    }\n",
        "\n",
        "    int *d_A, *d_B, *d_C;\n",
        "    cudaMalloc(&d_A, size);\n",
        "    cudaMalloc(&d_B, size);\n",
        "    cudaMalloc(&d_C, size);\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 threads(N, N);\n",
        "    dim3 blocks(1, 1);\n",
        "    matMul<<<blocks, threads>>>(d_A, d_B, d_C, N);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Result matrix C:\\n\");\n",
        "    for (int i = 0; i < N*N; ++i) {\n",
        "        printf(\"%d \", h_C[i]);\n",
        "        if ((i+1) % N == 0) printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 matrix_mul_colab.cu -o matrix_mul_colab\n",
        "!./matrix_mul_colab\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KHZbtBfq6gR",
        "outputId": "e6e6124f-7f36-4ca6-9be8-aa88727797e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result matrix C:\n",
            "60 72 84 \n",
            "132 162 192 \n",
            "204 252 300 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./matmul"
      ],
      "metadata": {
        "id": "HBPTU-u1q701"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_mul_colab1.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <time.h>\n",
        "\n",
        "// GPU Kernel for Matrix Multiplication\n",
        "__global__ void matMul(int *A, int *B, int *C, int n)\n",
        "{\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < n && col < n) {\n",
        "        int sum = 0;\n",
        "        for (int k = 0; k < n; k++) {\n",
        "            sum += A[row * n + k] * B[k * n + col];\n",
        "        }\n",
        "        C[row * n + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int N;\n",
        "    printf(\"Enter matrix size N for NxN matrix: \");\n",
        "    scanf(\"%d\", &N);\n",
        "\n",
        "    int size = N * N * sizeof(int);\n",
        "\n",
        "    // Dynamic allocation on CPU\n",
        "    int *h_A = (int *)malloc(size);\n",
        "    int *h_B = (int *)malloc(size);\n",
        "    int *h_C = (int *)malloc(size);\n",
        "    int *h_C_CPU = (int *)malloc(size);\n",
        "\n",
        "    // User input\n",
        "    printf(\"\\nEnter %d elements for Matrix A:\\n\", N*N);\n",
        "    for (int i = 0; i < N*N; i++)\n",
        "        scanf(\"%d\", &h_A[i]);\n",
        "\n",
        "    printf(\"\\nEnter %d elements for Matrix B:\\n\", N*N);\n",
        "    for (int i = 0; i < N*N; i++)\n",
        "        scanf(\"%d\", &h_B[i]);\n",
        "\n",
        "\n",
        "    // Measure CPU execution time\n",
        "    clock_t startCPU = clock();\n",
        "\n",
        "    // CPU matrix multiplication\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            int sum = 0;\n",
        "            for (int k = 0; k < N; k++) {\n",
        "                sum += h_A[i*N + k] * h_B[k*N + j];\n",
        "            }\n",
        "            h_C_CPU[i*N + j] = sum;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    clock_t endCPU = clock();\n",
        "    double cpu_time = ((double)(endCPU - startCPU) / CLOCKS_PER_SEC) * 1000.0;\n",
        "\n",
        "\n",
        "    // GPU Memory allocation\n",
        "    int *d_A, *d_B, *d_C;\n",
        "    cudaMalloc(&d_A, size);\n",
        "    cudaMalloc(&d_B, size);\n",
        "    cudaMalloc(&d_C, size);\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Query GPU hardware specifications\n",
        "    cudaDeviceProp prop;\n",
        "    cudaGetDeviceProperties(&prop, 0);\n",
        "    printf(\"\\nGPU Streaming Multiprocessors (SMs): %d\\n\", prop.multiProcessorCount);\n",
        "\n",
        "    // Block and grid configuration\n",
        "    dim3 threads(16, 16);\n",
        "    dim3 blocks((N + threads.x - 1) / threads.x,\n",
        "                (N + threads.y - 1) / threads.y);\n",
        "\n",
        "    printf(\"Threads per Block: %d x %d = %d\\n\", threads.x, threads.y, threads.x*threads.y);\n",
        "    printf(\"Blocks in Grid: %d x %d\\n\", blocks.x, blocks.y);\n",
        "\n",
        "    // GPU timing variables\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Start recording GPU time\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    // Launch kernel\n",
        "    matMul<<<blocks, threads>>>(d_A, d_B, d_C, N);\n",
        "\n",
        "    // Stop GPU timing\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float gpu_time = 0;\n",
        "    cudaEventElapsedTime(&gpu_time, start, stop);\n",
        "\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "\n",
        "    // Display output\n",
        "    printf(\"\\nResult Matrix from GPU (C = A x B):\\n\");\n",
        "    for (int i = 0; i < N*N; i++) {\n",
        "        printf(\"%d \", h_C[i]);\n",
        "        if ((i+1) % N == 0) printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    // Show timing results\n",
        "    printf(\"\\nCPU Execution Time: %.4f ms\\n\", cpu_time);\n",
        "    printf(\"GPU Execution Time: %.4f ms\\n\", gpu_time);\n",
        "\n",
        "    // Free memory\n",
        "    free(h_A); free(h_B); free(h_C); free(h_C_CPU);\n",
        "    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n",
        "\n",
        "    h_A = NULL;\n",
        "    h_B = NULL;\n",
        "    h_C = NULL;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aahy8cI5AwWQ",
        "outputId": "d95bd310-2bc2-4d73-e037-3507759bc087"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_mul_colab1.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3-4gr7aYCoZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 matrix_mul_colab1.cu -o matrix_mul_colab1\n",
        "!./matrix_mul_colab1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d29f8e8-80ce-4869-ce33-dfef1a6592fb",
        "id": "B15T6EzSCscX"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter matrix size N for NxN matrix: 10\n",
            "\n",
            "Enter 100 elements for Matrix A:\n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\n",
            "\n",
            "Enter 100 elements for Matrix B:\n",
            "2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100 102 104 106 108 110 112 114 116 118 120 122 124 126 128 130 132 134 136 138 140 142 144 146 148 150 152 154 156 158 160 162 164 166 168 170 172 174 176 178 180 182 184 186 188 190 192 194 196 198 200\n",
            "\n",
            "GPU Streaming Multiprocessors (SMs): 40\n",
            "Threads per Block: 16 x 16 = 256\n",
            "Blocks in Grid: 1 x 1\n",
            "\n",
            "Result Matrix from GPU (C = A x B):\n",
            "6710 6820 6930 7040 7150 7260 7370 7480 7590 7700 \n",
            "15910 16220 16530 16840 17150 17460 17770 18080 18390 18700 \n",
            "25110 25620 26130 26640 27150 27660 28170 28680 29190 29700 \n",
            "34310 35020 35730 36440 37150 37860 38570 39280 39990 40700 \n",
            "43510 44420 45330 46240 47150 48060 48970 49880 50790 51700 \n",
            "52710 53820 54930 56040 57150 58260 59370 60480 61590 62700 \n",
            "61910 63220 64530 65840 67150 68460 69770 71080 72390 73700 \n",
            "71110 72620 74130 75640 77150 78660 80170 81680 83190 84700 \n",
            "80310 82020 83730 85440 87150 88860 90570 92280 93990 95700 \n",
            "89510 91420 93330 95240 97150 99060 100970 102880 104790 106700 \n",
            "\n",
            "CPU Execution Time: 0.0050 ms\n",
            "GPU Execution Time: 0.1116 ms\n"
          ]
        }
      ]
    }
  ]
}